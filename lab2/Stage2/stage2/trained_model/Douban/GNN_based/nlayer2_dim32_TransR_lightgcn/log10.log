2023-02-10 20:46:58,027 - root - INFO - Namespace(KG_embedding_type='TransR', Ks='[5, 10]', aggregation_type='lightgcn', cf_batch_size=1024, cf_l2loss_lambda=0.0001, cf_print_every=1, cuda=False, data_dir='data/', data_name='Douban', embed_dim=32, evaluate_every=10, gpu_id=0, kg_batch_size=2048, kg_l2loss_lambda=1e-05, kg_print_every=1, laplacian_type='random-walk', lr=0.001, mess_dropout=0.1, n_epoch=10, n_layers=2, pretrain_model_path='trained_model/GNN_based.pth', relation_dim=32, save_dir='trained_model/Douban/GNN_based/nlayer2_dim32_TransR_lightgcn', seed=2022, stopping_steps=10, test_batch_size=2048, use_pretrain=0)
2023-02-10 20:46:58,027 - root - INFO - Running on cpu
2023-02-10 20:47:21,519 - root - INFO - n_users:           447
2023-02-10 20:47:21,522 - root - INFO - n_items:           578
2023-02-10 20:47:21,522 - root - INFO - n_entities:        18134
2023-02-10 20:47:21,522 - root - INFO - n_users_entities:  18581
2023-02-10 20:47:21,522 - root - INFO - n_relations:       450
2023-02-10 20:47:21,522 - root - INFO - n_cf_train:        41830
2023-02-10 20:47:21,528 - root - INFO - n_cf_test:         10840
2023-02-10 20:47:21,528 - root - INFO - n_kg_train:        351986
2023-02-10 20:47:22,548 - root - INFO - GNN_based(
  (entity_user_embed): Embedding(18581, 32)
  (relation_embed): Embedding(450, 32)
  (aggregator_layers): ModuleList(
    (0): Aggregator(
      (message_dropout): Dropout(p=0.1, inplace=False)
      (activation): LeakyReLU(negative_slope=0.01)
    )
    (1): Aggregator(
      (message_dropout): Dropout(p=0.1, inplace=False)
      (activation): LeakyReLU(negative_slope=0.01)
    )
  )
)
2023-02-10 20:47:22,680 - root - INFO - CF Training: Epoch 0001 Iter 0001 / 0041 | Time 0.1s | Iter Loss 0.6710 | Iter Mean Loss 0.6710
2023-02-10 20:47:22,811 - root - INFO - CF Training: Epoch 0001 Iter 0002 / 0041 | Time 0.1s | Iter Loss 0.6439 | Iter Mean Loss 0.6575
2023-02-10 20:47:22,943 - root - INFO - CF Training: Epoch 0001 Iter 0003 / 0041 | Time 0.1s | Iter Loss 0.6344 | Iter Mean Loss 0.6498
2023-02-10 20:47:23,072 - root - INFO - CF Training: Epoch 0001 Iter 0004 / 0041 | Time 0.1s | Iter Loss 0.6171 | Iter Mean Loss 0.6416
2023-02-10 20:47:23,195 - root - INFO - CF Training: Epoch 0001 Iter 0005 / 0041 | Time 0.1s | Iter Loss 0.6101 | Iter Mean Loss 0.6353
2023-02-10 20:47:23,315 - root - INFO - CF Training: Epoch 0001 Iter 0006 / 0041 | Time 0.1s | Iter Loss 0.5738 | Iter Mean Loss 0.6251
2023-02-10 20:47:23,446 - root - INFO - CF Training: Epoch 0001 Iter 0007 / 0041 | Time 0.1s | Iter Loss 0.5534 | Iter Mean Loss 0.6148
2023-02-10 20:47:23,560 - root - INFO - CF Training: Epoch 0001 Iter 0008 / 0041 | Time 0.1s | Iter Loss 0.5392 | Iter Mean Loss 0.6054
2023-02-10 20:47:23,671 - root - INFO - CF Training: Epoch 0001 Iter 0009 / 0041 | Time 0.1s | Iter Loss 0.5664 | Iter Mean Loss 0.6011
2023-02-10 20:47:23,802 - root - INFO - CF Training: Epoch 0001 Iter 0010 / 0041 | Time 0.1s | Iter Loss 0.5517 | Iter Mean Loss 0.5961
2023-02-10 20:47:23,923 - root - INFO - CF Training: Epoch 0001 Iter 0011 / 0041 | Time 0.1s | Iter Loss 0.5435 | Iter Mean Loss 0.5913
2023-02-10 20:47:24,066 - root - INFO - CF Training: Epoch 0001 Iter 0012 / 0041 | Time 0.1s | Iter Loss 0.5336 | Iter Mean Loss 0.5865
2023-02-10 20:47:24,197 - root - INFO - CF Training: Epoch 0001 Iter 0013 / 0041 | Time 0.1s | Iter Loss 0.5229 | Iter Mean Loss 0.5816
2023-02-10 20:47:24,329 - root - INFO - CF Training: Epoch 0001 Iter 0014 / 0041 | Time 0.1s | Iter Loss 0.5207 | Iter Mean Loss 0.5773
2023-02-10 20:47:24,471 - root - INFO - CF Training: Epoch 0001 Iter 0015 / 0041 | Time 0.1s | Iter Loss 0.5066 | Iter Mean Loss 0.5726
2023-02-10 20:47:24,582 - root - INFO - CF Training: Epoch 0001 Iter 0016 / 0041 | Time 0.1s | Iter Loss 0.5086 | Iter Mean Loss 0.5686
2023-02-10 20:47:24,704 - root - INFO - CF Training: Epoch 0001 Iter 0017 / 0041 | Time 0.1s | Iter Loss 0.5156 | Iter Mean Loss 0.5655
2023-02-10 20:47:24,833 - root - INFO - CF Training: Epoch 0001 Iter 0018 / 0041 | Time 0.1s | Iter Loss 0.5173 | Iter Mean Loss 0.5628
2023-02-10 20:47:24,977 - root - INFO - CF Training: Epoch 0001 Iter 0019 / 0041 | Time 0.1s | Iter Loss 0.4979 | Iter Mean Loss 0.5594
2023-02-10 20:47:25,119 - root - INFO - CF Training: Epoch 0001 Iter 0020 / 0041 | Time 0.1s | Iter Loss 0.4957 | Iter Mean Loss 0.5562
2023-02-10 20:47:25,269 - root - INFO - CF Training: Epoch 0001 Iter 0021 / 0041 | Time 0.1s | Iter Loss 0.4693 | Iter Mean Loss 0.5520
2023-02-10 20:47:25,393 - root - INFO - CF Training: Epoch 0001 Iter 0022 / 0041 | Time 0.1s | Iter Loss 0.4902 | Iter Mean Loss 0.5492
2023-02-10 20:47:25,514 - root - INFO - CF Training: Epoch 0001 Iter 0023 / 0041 | Time 0.1s | Iter Loss 0.4602 | Iter Mean Loss 0.5454
2023-02-10 20:47:25,625 - root - INFO - CF Training: Epoch 0001 Iter 0024 / 0041 | Time 0.1s | Iter Loss 0.4840 | Iter Mean Loss 0.5428
2023-02-10 20:47:25,757 - root - INFO - CF Training: Epoch 0001 Iter 0025 / 0041 | Time 0.1s | Iter Loss 0.4628 | Iter Mean Loss 0.5396
2023-02-10 20:47:25,889 - root - INFO - CF Training: Epoch 0001 Iter 0026 / 0041 | Time 0.1s | Iter Loss 0.4588 | Iter Mean Loss 0.5365
2023-02-10 20:47:26,020 - root - INFO - CF Training: Epoch 0001 Iter 0027 / 0041 | Time 0.1s | Iter Loss 0.4842 | Iter Mean Loss 0.5346
2023-02-10 20:47:26,152 - root - INFO - CF Training: Epoch 0001 Iter 0028 / 0041 | Time 0.1s | Iter Loss 0.4512 | Iter Mean Loss 0.5316
2023-02-10 20:47:26,274 - root - INFO - CF Training: Epoch 0001 Iter 0029 / 0041 | Time 0.1s | Iter Loss 0.4404 | Iter Mean Loss 0.5284
2023-02-10 20:47:26,405 - root - INFO - CF Training: Epoch 0001 Iter 0030 / 0041 | Time 0.1s | Iter Loss 0.4668 | Iter Mean Loss 0.5264
2023-02-10 20:47:26,526 - root - INFO - CF Training: Epoch 0001 Iter 0031 / 0041 | Time 0.1s | Iter Loss 0.4622 | Iter Mean Loss 0.5243
2023-02-10 20:47:26,658 - root - INFO - CF Training: Epoch 0001 Iter 0032 / 0041 | Time 0.1s | Iter Loss 0.4596 | Iter Mean Loss 0.5223
2023-02-10 20:47:26,787 - root - INFO - CF Training: Epoch 0001 Iter 0033 / 0041 | Time 0.1s | Iter Loss 0.4578 | Iter Mean Loss 0.5203
2023-02-10 20:47:26,921 - root - INFO - CF Training: Epoch 0001 Iter 0034 / 0041 | Time 0.1s | Iter Loss 0.4547 | Iter Mean Loss 0.5184
2023-02-10 20:47:27,062 - root - INFO - CF Training: Epoch 0001 Iter 0035 / 0041 | Time 0.1s | Iter Loss 0.4534 | Iter Mean Loss 0.5165
2023-02-10 20:47:27,173 - root - INFO - CF Training: Epoch 0001 Iter 0036 / 0041 | Time 0.1s | Iter Loss 0.4543 | Iter Mean Loss 0.5148
2023-02-10 20:47:27,305 - root - INFO - CF Training: Epoch 0001 Iter 0037 / 0041 | Time 0.1s | Iter Loss 0.4357 | Iter Mean Loss 0.5127
2023-02-10 20:47:27,446 - root - INFO - CF Training: Epoch 0001 Iter 0038 / 0041 | Time 0.1s | Iter Loss 0.4469 | Iter Mean Loss 0.5109
2023-02-10 20:47:27,565 - root - INFO - CF Training: Epoch 0001 Iter 0039 / 0041 | Time 0.1s | Iter Loss 0.4655 | Iter Mean Loss 0.5098
2023-02-10 20:47:27,707 - root - INFO - CF Training: Epoch 0001 Iter 0040 / 0041 | Time 0.1s | Iter Loss 0.4053 | Iter Mean Loss 0.5072
2023-02-10 20:47:27,820 - root - INFO - CF Training: Epoch 0001 Iter 0041 / 0041 | Time 0.1s | Iter Loss 0.4347 | Iter Mean Loss 0.5054
2023-02-10 20:47:27,820 - root - INFO - CF Training: Epoch 0001 Total Iter 0041 | Total Time 5.3s | Iter Mean Loss 0.5054
