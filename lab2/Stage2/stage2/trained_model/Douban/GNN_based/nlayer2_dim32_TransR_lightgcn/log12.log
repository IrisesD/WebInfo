2023-02-10 20:49:38,292 - root - INFO - Namespace(KG_embedding_type='TransR', Ks='[5, 10]', aggregation_type='lightgcn', cf_batch_size=1024, cf_l2loss_lambda=0.0001, cf_print_every=1, cuda=False, data_dir='data/', data_name='Douban', embed_dim=32, evaluate_every=10, gpu_id=0, kg_batch_size=2048, kg_l2loss_lambda=1e-05, kg_print_every=1, laplacian_type='random-walk', lr=0.001, mess_dropout=0.1, n_epoch=10, n_layers=2, pretrain_model_path='trained_model/GNN_based.pth', relation_dim=32, save_dir='trained_model/Douban/GNN_based/nlayer2_dim32_TransR_lightgcn', seed=2022, stopping_steps=10, test_batch_size=2048, use_pretrain=0)
2023-02-10 20:49:38,292 - root - INFO - Running on cpu
2023-02-10 20:50:02,322 - root - INFO - n_users:           447
2023-02-10 20:50:02,324 - root - INFO - n_items:           578
2023-02-10 20:50:02,324 - root - INFO - n_entities:        18134
2023-02-10 20:50:02,324 - root - INFO - n_users_entities:  18581
2023-02-10 20:50:02,324 - root - INFO - n_relations:       450
2023-02-10 20:50:02,324 - root - INFO - n_cf_train:        41830
2023-02-10 20:50:02,324 - root - INFO - n_cf_test:         10840
2023-02-10 20:50:02,324 - root - INFO - n_kg_train:        351986
2023-02-10 20:50:03,353 - root - INFO - GNN_based(
  (entity_user_embed): Embedding(18581, 32)
  (relation_embed): Embedding(450, 32)
  (aggregator_layers): ModuleList(
    (0): Aggregator(
      (message_dropout): Dropout(p=0.1, inplace=False)
      (activation): LeakyReLU(negative_slope=0.01)
    )
    (1): Aggregator(
      (message_dropout): Dropout(p=0.1, inplace=False)
      (activation): LeakyReLU(negative_slope=0.01)
    )
  )
)
2023-02-10 20:50:03,474 - root - INFO - CF Training: Epoch 0001 Iter 0001 / 0041 | Time 0.1s | Iter Loss 0.6710 | Iter Mean Loss 0.6710
2023-02-10 20:50:03,596 - root - INFO - CF Training: Epoch 0001 Iter 0002 / 0041 | Time 0.1s | Iter Loss 0.6439 | Iter Mean Loss 0.6575
2023-02-10 20:50:03,717 - root - INFO - CF Training: Epoch 0001 Iter 0003 / 0041 | Time 0.1s | Iter Loss 0.6344 | Iter Mean Loss 0.6498
2023-02-10 20:50:03,828 - root - INFO - CF Training: Epoch 0001 Iter 0004 / 0041 | Time 0.1s | Iter Loss 0.6171 | Iter Mean Loss 0.6416
2023-02-10 20:50:03,970 - root - INFO - CF Training: Epoch 0001 Iter 0005 / 0041 | Time 0.1s | Iter Loss 0.6101 | Iter Mean Loss 0.6353
2023-02-10 20:50:04,101 - root - INFO - CF Training: Epoch 0001 Iter 0006 / 0041 | Time 0.1s | Iter Loss 0.5738 | Iter Mean Loss 0.6251
2023-02-10 20:50:04,232 - root - INFO - CF Training: Epoch 0001 Iter 0007 / 0041 | Time 0.1s | Iter Loss 0.5534 | Iter Mean Loss 0.6148
2023-02-10 20:50:04,362 - root - INFO - CF Training: Epoch 0001 Iter 0008 / 0041 | Time 0.1s | Iter Loss 0.5392 | Iter Mean Loss 0.6054
2023-02-10 20:50:04,475 - root - INFO - CF Training: Epoch 0001 Iter 0009 / 0041 | Time 0.1s | Iter Loss 0.5664 | Iter Mean Loss 0.6011
2023-02-10 20:50:04,607 - root - INFO - CF Training: Epoch 0001 Iter 0010 / 0041 | Time 0.1s | Iter Loss 0.5517 | Iter Mean Loss 0.5961
2023-02-10 20:50:04,729 - root - INFO - CF Training: Epoch 0001 Iter 0011 / 0041 | Time 0.1s | Iter Loss 0.5435 | Iter Mean Loss 0.5913
2023-02-10 20:50:04,859 - root - INFO - CF Training: Epoch 0001 Iter 0012 / 0041 | Time 0.1s | Iter Loss 0.5336 | Iter Mean Loss 0.5865
2023-02-10 20:50:05,001 - root - INFO - CF Training: Epoch 0001 Iter 0013 / 0041 | Time 0.1s | Iter Loss 0.5229 | Iter Mean Loss 0.5816
2023-02-10 20:50:05,122 - root - INFO - CF Training: Epoch 0001 Iter 0014 / 0041 | Time 0.1s | Iter Loss 0.5207 | Iter Mean Loss 0.5773
2023-02-10 20:50:05,254 - root - INFO - CF Training: Epoch 0001 Iter 0015 / 0041 | Time 0.1s | Iter Loss 0.5066 | Iter Mean Loss 0.5726
2023-02-10 20:50:05,385 - root - INFO - CF Training: Epoch 0001 Iter 0016 / 0041 | Time 0.1s | Iter Loss 0.5086 | Iter Mean Loss 0.5686
2023-02-10 20:50:05,517 - root - INFO - CF Training: Epoch 0001 Iter 0017 / 0041 | Time 0.1s | Iter Loss 0.5156 | Iter Mean Loss 0.5655
2023-02-10 20:50:05,628 - root - INFO - CF Training: Epoch 0001 Iter 0018 / 0041 | Time 0.1s | Iter Loss 0.5173 | Iter Mean Loss 0.5628
2023-02-10 20:50:05,760 - root - INFO - CF Training: Epoch 0001 Iter 0019 / 0041 | Time 0.1s | Iter Loss 0.4979 | Iter Mean Loss 0.5594
2023-02-10 20:50:05,901 - root - INFO - CF Training: Epoch 0001 Iter 0020 / 0041 | Time 0.1s | Iter Loss 0.4957 | Iter Mean Loss 0.5562
2023-02-10 20:50:06,033 - root - INFO - CF Training: Epoch 0001 Iter 0021 / 0041 | Time 0.1s | Iter Loss 0.4693 | Iter Mean Loss 0.5520
2023-02-10 20:50:06,172 - root - INFO - CF Training: Epoch 0001 Iter 0022 / 0041 | Time 0.1s | Iter Loss 0.4902 | Iter Mean Loss 0.5492
2023-02-10 20:50:06,295 - root - INFO - CF Training: Epoch 0001 Iter 0023 / 0041 | Time 0.1s | Iter Loss 0.4602 | Iter Mean Loss 0.5454
2023-02-10 20:50:06,397 - root - INFO - CF Training: Epoch 0001 Iter 0024 / 0041 | Time 0.1s | Iter Loss 0.4840 | Iter Mean Loss 0.5428
2023-02-10 20:50:06,508 - root - INFO - CF Training: Epoch 0001 Iter 0025 / 0041 | Time 0.1s | Iter Loss 0.4628 | Iter Mean Loss 0.5396
2023-02-10 20:50:06,650 - root - INFO - CF Training: Epoch 0001 Iter 0026 / 0041 | Time 0.1s | Iter Loss 0.4588 | Iter Mean Loss 0.5365
2023-02-10 20:50:06,781 - root - INFO - CF Training: Epoch 0001 Iter 0027 / 0041 | Time 0.1s | Iter Loss 0.4842 | Iter Mean Loss 0.5346
2023-02-10 20:50:06,913 - root - INFO - CF Training: Epoch 0001 Iter 0028 / 0041 | Time 0.1s | Iter Loss 0.4512 | Iter Mean Loss 0.5316
2023-02-10 20:50:07,054 - root - INFO - CF Training: Epoch 0001 Iter 0029 / 0041 | Time 0.1s | Iter Loss 0.4404 | Iter Mean Loss 0.5284
2023-02-10 20:50:07,176 - root - INFO - CF Training: Epoch 0001 Iter 0030 / 0041 | Time 0.1s | Iter Loss 0.4668 | Iter Mean Loss 0.5264
2023-02-10 20:50:07,297 - root - INFO - CF Training: Epoch 0001 Iter 0031 / 0041 | Time 0.1s | Iter Loss 0.4622 | Iter Mean Loss 0.5243
2023-02-10 20:50:07,429 - root - INFO - CF Training: Epoch 0001 Iter 0032 / 0041 | Time 0.1s | Iter Loss 0.4596 | Iter Mean Loss 0.5223
2023-02-10 20:50:07,560 - root - INFO - CF Training: Epoch 0001 Iter 0033 / 0041 | Time 0.1s | Iter Loss 0.4578 | Iter Mean Loss 0.5203
2023-02-10 20:50:07,691 - root - INFO - CF Training: Epoch 0001 Iter 0034 / 0041 | Time 0.1s | Iter Loss 0.4547 | Iter Mean Loss 0.5184
2023-02-10 20:50:07,823 - root - INFO - CF Training: Epoch 0001 Iter 0035 / 0041 | Time 0.1s | Iter Loss 0.4534 | Iter Mean Loss 0.5165
2023-02-10 20:50:07,954 - root - INFO - CF Training: Epoch 0001 Iter 0036 / 0041 | Time 0.1s | Iter Loss 0.4543 | Iter Mean Loss 0.5148
2023-02-10 20:50:08,075 - root - INFO - CF Training: Epoch 0001 Iter 0037 / 0041 | Time 0.1s | Iter Loss 0.4357 | Iter Mean Loss 0.5127
2023-02-10 20:50:08,187 - root - INFO - CF Training: Epoch 0001 Iter 0038 / 0041 | Time 0.1s | Iter Loss 0.4469 | Iter Mean Loss 0.5109
2023-02-10 20:50:08,318 - root - INFO - CF Training: Epoch 0001 Iter 0039 / 0041 | Time 0.1s | Iter Loss 0.4655 | Iter Mean Loss 0.5098
2023-02-10 20:50:08,449 - root - INFO - CF Training: Epoch 0001 Iter 0040 / 0041 | Time 0.1s | Iter Loss 0.4053 | Iter Mean Loss 0.5072
2023-02-10 20:50:08,581 - root - INFO - CF Training: Epoch 0001 Iter 0041 / 0041 | Time 0.1s | Iter Loss 0.4347 | Iter Mean Loss 0.5054
2023-02-10 20:50:08,581 - root - INFO - CF Training: Epoch 0001 Total Iter 0041 | Total Time 5.2s | Iter Mean Loss 0.5054
2023-02-10 20:50:08,753 - root - INFO - KG Training: Epoch 0001 Iter 0001 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:08,932 - root - INFO - KG Training: Epoch 0001 Iter 0002 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:09,114 - root - INFO - KG Training: Epoch 0001 Iter 0003 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:09,298 - root - INFO - KG Training: Epoch 0001 Iter 0004 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:09,479 - root - INFO - KG Training: Epoch 0001 Iter 0005 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:09,661 - root - INFO - KG Training: Epoch 0001 Iter 0006 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:09,823 - root - INFO - KG Training: Epoch 0001 Iter 0007 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:10,014 - root - INFO - KG Training: Epoch 0001 Iter 0008 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:10,196 - root - INFO - KG Training: Epoch 0001 Iter 0009 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:10,378 - root - INFO - KG Training: Epoch 0001 Iter 0010 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:10,560 - root - INFO - KG Training: Epoch 0001 Iter 0011 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:10,722 - root - INFO - KG Training: Epoch 0001 Iter 0012 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:10,903 - root - INFO - KG Training: Epoch 0001 Iter 0013 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:11,096 - root - INFO - KG Training: Epoch 0001 Iter 0014 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:11,267 - root - INFO - KG Training: Epoch 0001 Iter 0015 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:11,439 - root - INFO - KG Training: Epoch 0001 Iter 0016 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:11,610 - root - INFO - KG Training: Epoch 0001 Iter 0017 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:11,802 - root - INFO - KG Training: Epoch 0001 Iter 0018 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:11,983 - root - INFO - KG Training: Epoch 0001 Iter 0019 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
2023-02-10 20:50:12,155 - root - INFO - KG Training: Epoch 0001 Iter 0020 / 0172 | Time 0.2s | Iter Loss 0.0000 | Iter Mean Loss 0.0000
