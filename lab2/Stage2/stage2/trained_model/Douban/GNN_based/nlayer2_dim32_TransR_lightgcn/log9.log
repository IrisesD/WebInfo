2023-02-10 20:43:08,683 - root - INFO - Namespace(KG_embedding_type='TransR', Ks='[5, 10]', aggregation_type='lightgcn', cf_batch_size=1024, cf_l2loss_lambda=0.0001, cf_print_every=1, cuda=False, data_dir='data/', data_name='Douban', embed_dim=32, evaluate_every=10, gpu_id=0, kg_batch_size=2048, kg_l2loss_lambda=1e-05, kg_print_every=1, laplacian_type='random-walk', lr=0.001, mess_dropout=0.1, n_epoch=10, n_layers=2, pretrain_model_path='trained_model/GNN_based.pth', relation_dim=32, save_dir='trained_model/Douban/GNN_based/nlayer2_dim32_TransR_lightgcn', seed=2022, stopping_steps=10, test_batch_size=2048, use_pretrain=0)
2023-02-10 20:43:08,683 - root - INFO - Running on cpu
2023-02-10 20:43:32,035 - root - INFO - n_users:           447
2023-02-10 20:43:32,043 - root - INFO - n_items:           578
2023-02-10 20:43:32,043 - root - INFO - n_entities:        18134
2023-02-10 20:43:32,043 - root - INFO - n_users_entities:  18581
2023-02-10 20:43:32,043 - root - INFO - n_relations:       450
2023-02-10 20:43:32,043 - root - INFO - n_cf_train:        41830
2023-02-10 20:43:32,043 - root - INFO - n_cf_test:         10840
2023-02-10 20:43:32,043 - root - INFO - n_kg_train:        351986
2023-02-10 20:43:33,087 - root - INFO - GNN_based(
  (entity_user_embed): Embedding(18581, 32)
  (relation_embed): Embedding(450, 32)
  (aggregator_layers): ModuleList(
    (0): Aggregator(
      (message_dropout): Dropout(p=0.1, inplace=False)
      (activation): LeakyReLU(negative_slope=0.01)
    )
    (1): Aggregator(
      (message_dropout): Dropout(p=0.1, inplace=False)
      (activation): LeakyReLU(negative_slope=0.01)
    )
  )
)
2023-02-10 20:43:33,219 - root - INFO - CF Training: Epoch 0001 Iter 0001 / 0041 | Time 0.1s | Iter Loss 0.6710 | Iter Mean Loss 0.6710
2023-02-10 20:43:33,357 - root - INFO - CF Training: Epoch 0001 Iter 0002 / 0041 | Time 0.1s | Iter Loss 0.6439 | Iter Mean Loss 0.6575
2023-02-10 20:43:33,479 - root - INFO - CF Training: Epoch 0001 Iter 0003 / 0041 | Time 0.1s | Iter Loss 0.6344 | Iter Mean Loss 0.6498
2023-02-10 20:43:33,601 - root - INFO - CF Training: Epoch 0001 Iter 0004 / 0041 | Time 0.1s | Iter Loss 0.6171 | Iter Mean Loss 0.6416
2023-02-10 20:43:33,722 - root - INFO - CF Training: Epoch 0001 Iter 0005 / 0041 | Time 0.1s | Iter Loss 0.6101 | Iter Mean Loss 0.6353
2023-02-10 20:43:33,833 - root - INFO - CF Training: Epoch 0001 Iter 0006 / 0041 | Time 0.1s | Iter Loss 0.5738 | Iter Mean Loss 0.6251
2023-02-10 20:43:33,955 - root - INFO - CF Training: Epoch 0001 Iter 0007 / 0041 | Time 0.1s | Iter Loss 0.5534 | Iter Mean Loss 0.6148
2023-02-10 20:43:34,076 - root - INFO - CF Training: Epoch 0001 Iter 0008 / 0041 | Time 0.1s | Iter Loss 0.5392 | Iter Mean Loss 0.6054
2023-02-10 20:43:34,208 - root - INFO - CF Training: Epoch 0001 Iter 0009 / 0041 | Time 0.1s | Iter Loss 0.5664 | Iter Mean Loss 0.6011
2023-02-10 20:43:34,329 - root - INFO - CF Training: Epoch 0001 Iter 0010 / 0041 | Time 0.1s | Iter Loss 0.5517 | Iter Mean Loss 0.5961
2023-02-10 20:43:34,449 - root - INFO - CF Training: Epoch 0001 Iter 0011 / 0041 | Time 0.1s | Iter Loss 0.5435 | Iter Mean Loss 0.5913
2023-02-10 20:43:34,572 - root - INFO - CF Training: Epoch 0001 Iter 0012 / 0041 | Time 0.1s | Iter Loss 0.5336 | Iter Mean Loss 0.5865
2023-02-10 20:43:34,724 - root - INFO - CF Training: Epoch 0001 Iter 0013 / 0041 | Time 0.2s | Iter Loss 0.5229 | Iter Mean Loss 0.5816
2023-02-10 20:43:34,843 - root - INFO - CF Training: Epoch 0001 Iter 0014 / 0041 | Time 0.1s | Iter Loss 0.5207 | Iter Mean Loss 0.5773
2023-02-10 20:43:34,977 - root - INFO - CF Training: Epoch 0001 Iter 0015 / 0041 | Time 0.1s | Iter Loss 0.5066 | Iter Mean Loss 0.5726
2023-02-10 20:43:35,098 - root - INFO - CF Training: Epoch 0001 Iter 0016 / 0041 | Time 0.1s | Iter Loss 0.5086 | Iter Mean Loss 0.5686
2023-02-10 20:43:35,230 - root - INFO - CF Training: Epoch 0001 Iter 0017 / 0041 | Time 0.1s | Iter Loss 0.5156 | Iter Mean Loss 0.5655
2023-02-10 20:43:35,361 - root - INFO - CF Training: Epoch 0001 Iter 0018 / 0041 | Time 0.1s | Iter Loss 0.5173 | Iter Mean Loss 0.5628
2023-02-10 20:43:35,493 - root - INFO - CF Training: Epoch 0001 Iter 0019 / 0041 | Time 0.1s | Iter Loss 0.4979 | Iter Mean Loss 0.5594
2023-02-10 20:43:35,642 - root - INFO - CF Training: Epoch 0001 Iter 0020 / 0041 | Time 0.1s | Iter Loss 0.4957 | Iter Mean Loss 0.5562
2023-02-10 20:43:35,776 - root - INFO - CF Training: Epoch 0001 Iter 0021 / 0041 | Time 0.1s | Iter Loss 0.4693 | Iter Mean Loss 0.5520
2023-02-10 20:43:35,897 - root - INFO - CF Training: Epoch 0001 Iter 0022 / 0041 | Time 0.1s | Iter Loss 0.4902 | Iter Mean Loss 0.5492
2023-02-10 20:43:36,027 - root - INFO - CF Training: Epoch 0001 Iter 0023 / 0041 | Time 0.1s | Iter Loss 0.4602 | Iter Mean Loss 0.5454
2023-02-10 20:43:36,150 - root - INFO - CF Training: Epoch 0001 Iter 0024 / 0041 | Time 0.1s | Iter Loss 0.4840 | Iter Mean Loss 0.5428
2023-02-10 20:43:36,282 - root - INFO - CF Training: Epoch 0001 Iter 0025 / 0041 | Time 0.1s | Iter Loss 0.4628 | Iter Mean Loss 0.5396
2023-02-10 20:43:36,393 - root - INFO - CF Training: Epoch 0001 Iter 0026 / 0041 | Time 0.1s | Iter Loss 0.4588 | Iter Mean Loss 0.5365
2023-02-10 20:43:36,514 - root - INFO - CF Training: Epoch 0001 Iter 0027 / 0041 | Time 0.1s | Iter Loss 0.4842 | Iter Mean Loss 0.5346
2023-02-10 20:43:36,646 - root - INFO - CF Training: Epoch 0001 Iter 0028 / 0041 | Time 0.1s | Iter Loss 0.4512 | Iter Mean Loss 0.5316
2023-02-10 20:43:36,785 - root - INFO - CF Training: Epoch 0001 Iter 0029 / 0041 | Time 0.1s | Iter Loss 0.4404 | Iter Mean Loss 0.5284
2023-02-10 20:43:36,919 - root - INFO - CF Training: Epoch 0001 Iter 0030 / 0041 | Time 0.1s | Iter Loss 0.4668 | Iter Mean Loss 0.5264
2023-02-10 20:43:37,060 - root - INFO - CF Training: Epoch 0001 Iter 0031 / 0041 | Time 0.1s | Iter Loss 0.4622 | Iter Mean Loss 0.5243
2023-02-10 20:43:37,181 - root - INFO - CF Training: Epoch 0001 Iter 0032 / 0041 | Time 0.1s | Iter Loss 0.4596 | Iter Mean Loss 0.5223
2023-02-10 20:43:37,321 - root - INFO - CF Training: Epoch 0001 Iter 0033 / 0041 | Time 0.1s | Iter Loss 0.4578 | Iter Mean Loss 0.5203
2023-02-10 20:43:37,455 - root - INFO - CF Training: Epoch 0001 Iter 0034 / 0041 | Time 0.1s | Iter Loss 0.4547 | Iter Mean Loss 0.5184
2023-02-10 20:43:37,576 - root - INFO - CF Training: Epoch 0001 Iter 0035 / 0041 | Time 0.1s | Iter Loss 0.4534 | Iter Mean Loss 0.5165
2023-02-10 20:43:37,718 - root - INFO - CF Training: Epoch 0001 Iter 0036 / 0041 | Time 0.1s | Iter Loss 0.4543 | Iter Mean Loss 0.5148
2023-02-10 20:43:37,839 - root - INFO - CF Training: Epoch 0001 Iter 0037 / 0041 | Time 0.1s | Iter Loss 0.4357 | Iter Mean Loss 0.5127
2023-02-10 20:43:37,971 - root - INFO - CF Training: Epoch 0001 Iter 0038 / 0041 | Time 0.1s | Iter Loss 0.4469 | Iter Mean Loss 0.5109
2023-02-10 20:43:38,092 - root - INFO - CF Training: Epoch 0001 Iter 0039 / 0041 | Time 0.1s | Iter Loss 0.4655 | Iter Mean Loss 0.5098
2023-02-10 20:43:38,224 - root - INFO - CF Training: Epoch 0001 Iter 0040 / 0041 | Time 0.1s | Iter Loss 0.4053 | Iter Mean Loss 0.5072
2023-02-10 20:43:38,355 - root - INFO - CF Training: Epoch 0001 Iter 0041 / 0041 | Time 0.1s | Iter Loss 0.4347 | Iter Mean Loss 0.5054
2023-02-10 20:43:38,355 - root - INFO - CF Training: Epoch 0001 Total Iter 0041 | Total Time 5.3s | Iter Mean Loss 0.5054
